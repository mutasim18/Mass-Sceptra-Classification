{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'global_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# For CM1\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Import required libraries\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnbimporter\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglobal_functions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgf\u001b[39;00m  \u001b[38;5;66;03m# Import global functions from global_functions.ipynb\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlgb\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_auc_score, accuracy_score, classification_report\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'global_functions'"
     ]
    }
   ],
   "source": [
    "# For CM1\n",
    "# Import required libraries\n",
    "import nbimporter\n",
    "import global_functions as gf  # Import global functions from global_functions.ipynb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Paths to datasets\n",
    "dataset_paths = r\"C:\\Local Disk (A)\\Github Files\\Projects\\Mass-Sceptra-Classification\\Datasets\\CM1\"\n",
    "\n",
    "\n",
    "# Main execution block\n",
    "def process_dataset(base_path):\n",
    "    \"\"\"Process a single dataset, train and evaluate LightGBM model.\"\"\"\n",
    "    print(f\"\\nProcessing dataset at {base_path}...\")\n",
    "\n",
    "    # Prepare dataset using global function\n",
    "    X_train, X_test, y_train, y_test, scaler = gf.prepare_dataset(base_path)\n",
    "    if X_train is None:\n",
    "        print(f\"No valid data found at {base_path}. Skipping...\")\n",
    "        return\n",
    "\n",
    "    # Initialize LightGBM dataset\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "    # Define LightGBM parameters\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': 0.01,\n",
    "        'num_leaves': 31,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'max_depth': -1,\n",
    "        'verbosity': -1,\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    # Train LightGBM model\n",
    "    print(\"\\nTraining LightGBM model...\")\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        valid_sets=[train_data, test_data],\n",
    "        num_boost_round=1000,\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=100\n",
    "    )\n",
    "\n",
    "    # Make predictions\n",
    "    print(\"\\nEvaluating model...\")\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "    y_prob = model.predict(X_test)\n",
    "\n",
    "    # Evaluation metrics\n",
    "    print(\"\\nTest Set Performance:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, y_prob):.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Plot feature importance\n",
    "    print(\"\\nPlotting feature importance...\")\n",
    "    lgb.plot_importance(model, max_num_features=10, importance_type='gain')\n",
    "    plt.title('Feature Importance')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot confusion matrix using a function from global_functions\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    gf.plot_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Save the model for the current dataset\n",
    "    model_filename = base_path.split(\"\\\\\")[-1] + \"_lightgbm_model.txt\"\n",
    "    model.save_model(model_filename)\n",
    "    print(f\"Model saved as {model_filename}.\")\n",
    "\n",
    "# Run processing for each dataset\n",
    "for dataset_path in dataset_paths:\n",
    "    process_dataset(dataset_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
